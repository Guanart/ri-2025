# Mejoras Implementadas - Par√°metro preserve_query

## Resumen de Cambios

Se ha agregado exitosamente el par√°metro `preserve_query` a ambos ejercicios del TP05, completando as√≠ todas las mejoras solicitadas.

## Cambios Realizados

### Ejercicio 1 (ejercicio1.py)
- ‚úÖ **Agregado par√°metro `--preserve-query`**: Nuevo argumento opcional de l√≠nea de comandos
- ‚úÖ **Valor por defecto**: `preserve_query=False` (comportamiento m√°s com√∫n)
- ‚úÖ **Configuraci√≥n mostrada**: Se muestra la configuraci√≥n antes de ejecutar el crawler

**Uso:**
```bash
# Sin preservar query strings (por defecto)
python3 ejercicio1.py "https://example.com/page?param=value"

# Preservando query strings
python3 ejercicio1.py "https://example.com/page?param=value" --preserve-query
```

### Ejercicio 2 (ejercicio2.py)
- ‚úÖ **Input interactivo**: Nueva pregunta para elegir si preservar query strings
- ‚úÖ **Configuraci√≥n en crawlers**: Par√°metro pasado tanto a `Crawler` como `CrawlerParallel`
- ‚úÖ **Nombres de archivos**: Incluye `query` o `noquery` en los nombres de archivos de salida
- ‚úÖ **Informaci√≥n mostrada**: Se muestra la configuraci√≥n durante el crawling

**Nombres de archivos generados:**
- `ejercicio2_sequential_150p_query.pkl` (con preserve_query=True)
- `ejercicio2_sequential_150p_noquery.pkl` (con preserve_query=False)
- `ejercicio2_parallel_150p_query_graph.html` (con preserve_query=True)
- `ejercicio2_parallel_150p_noquery_graph.html` (con preserve_query=False)

## Par√°metros Configurables Completos

### Ejercicio 1
1. **URL**: URL a analizar (argumento posicional)
2. **preserve_query**: Preservar query strings (--preserve-query)

### Ejercicio 2
1. **Tipo de crawler**: Secuencial o paralelo (input interactivo)
2. **Workers paralelos**: 2-12 workers (solo para crawler paralelo)
3. **preserve_query**: Preservar query strings (input interactivo)
4. **Cantidad de p√°ginas**: 50, 150, 500 o personalizado
5. **P√°ginas por sitio**: 20-50 p√°ginas por dominio

## Impacto del Par√°metro preserve_query

### preserve_query=False (Recomendado por defecto)
- **Ventajas**: Menos URLs duplicadas, crawling m√°s eficiente
- **Comportamiento**: Elimina query strings y fragments de las URLs
- **Uso t√≠pico**: Crawling general, an√°lisis de estructura de sitios

**Ejemplo:**
- URL original: `https://example.com/search?q=python&page=2#results`
- URL procesada: `https://example.com/search`

### preserve_query=True (Para casos espec√≠ficos)
- **Ventajas**: Mantiene contexto de p√°ginas din√°micas espec√≠ficas
- **Comportamiento**: Preserva query strings, solo elimina fragments
- **Uso t√≠pico**: An√°lisis de p√°ginas de b√∫squeda, APIs, p√°ginas param√©tricas

**Ejemplo:**
- URL original: `https://example.com/search?q=python&page=2#results`
- URL procesada: `https://example.com/search?q=python&page=2`

## Verificaci√≥n de Funcionamiento

### Tests Implementados
1. **test_preserve_query_quick.sh**: Script de prueba r√°pida
2. **test_preserve_query.py**: Test completo comparativo existente

### Verificaci√≥n Manual
```bash
# Test b√°sico de funcionamiento
cd /home/gbenito/universidad/ri-2025/TP05\ -\ Crawling
python3 -c "
from lib.Crawler import Crawler
from lib.CrawlerParallel import CrawlerParallel
c1 = Crawler(preserve_query=True)
c2 = CrawlerParallel(preserve_query=False)
print('‚úÖ Tests b√°sicos OK')
"
```

## Estado Final

### ‚úÖ Completado
- [x] Elegir entre Crawler secuencial y paralelo (ejercicio 2)
- [x] Configurar cantidad de p√°ginas totales
- [x] Configurar p√°ginas por sitio  
- [x] Configurar cantidad de workers (crawler paralelo)
- [x] **Configurar preserve_query (NUEVO)**
- [x] Mostrar todos los nodos en visualizaci√≥n
- [x] Nombres de archivos descriptivos
- [x] Scripts claros y flexibles para experimentaci√≥n

### Archivos Modificados
- `ejercicio1/ejercicio1.py`: Agregado par√°metro --preserve-query
- `ejercicio2/ejercicio2.py`: Agregado input interactivo y configuraci√≥n completa
- `test_preserve_query_quick.sh`: Script de verificaci√≥n (NUEVO)

### Archivos de Salida Mejorados
Los nombres de archivos ahora incluyen toda la configuraci√≥n:
- Tipo de crawler: `sequential` o `parallel`
- Cantidad de p√°ginas: `150p`, `500p`, etc.
- Query handling: `query` o `noquery`

**Ejemplo**: `ejercicio2_parallel_500p_noquery_graph.html`

## Recomendaciones de Uso

1. **Para crawling general**: `preserve_query=False` (m√°s eficiente)
2. **Para an√°lisis de b√∫squedas**: `preserve_query=True` (m√°s detallado)
3. **Para comparaciones**: Ejecutar ambas versiones y comparar resultados
4. **Para experimentaci√≥n**: Usar nombres de archivos descriptivos para organizar experimentos

¬°Todas las mejoras solicitadas han sido implementadas exitosamente! üéâ
